is.na(num_music_reviews) ~ 0
)
) |>
filter(!is.na(music_treatment)) |> # for now
relocate(num_music_reviews, music_treatment, restaurant_or_bar)
cleaned_business_data |>
filter(num_music_reviews > 1 & !restaurant_or_bar) |>
count() # number of non-restaurants or bars in treatment: 603
cleaned_business_data |>
filter(music_treatment == 1) |>
count() # how many offer live music: 3610
# restaurants_and_bars ----------------------------------------------------
restaurants_and_bars <- cleaned_business_data |>
filter(restaurant_or_bar == 1) |>
select(!restaurant_or_bar)
# share of music places
# and xi is share of restaurants and bars
# we can compare across cities.
TOTAL_RB <- restaurants_and_bars |>
nrow()
x_i <- restaurants_and_bars |>
group_by(city) |>
summarize(
num_rb = n()
) |>
mutate(
x_i = num_rb / TOTAL_RB
)
TOTAL_MUSIC <- restaurants_and_bars |>
filter(music_treatment == 1) |>
nrow()
s_i <- restaurants_and_bars |>
filter(music_treatment == 1) |>
group_by(city) |>
summarize(
num_music = n()
) |>
mutate(
s_i = num_music / TOTAL_MUSIC
)
View(s_i)
?relocate
L_i <- x_i |>
inner_join(s_i) |>
relocate(city, num_rb, num_music, s_i, x_i) |>
mutate(
L_i = s_i / x_i
)
L_i <- x_i |>
inner_join(s_i, by = "city") |>
relocate(city, num_rb, num_music, s_i, x_i) |>
mutate(
L_i = s_i / x_i
)
View(L_i)
L_i <- x_i |>
inner_join(s_i, by = "city") |>
relocate(city, num_music, num_rb, s_i, x_i) |>
mutate(
L_i = s_i / x_i
)
location_quotients <- x_i |>
inner_join(s_i, by = "city") |>
relocate(city, num_music, num_rb, s_i, x_i) |>
mutate(
L_i = s_i / x_i
)
location_quotients <- x_i |>
inner_join(s_i, by = "city") |>
relocate(city, num_music, num_rb, s_i, x_i) |>
mutate(
l_i = s_i / x_i
)
gini <- location_quotients |>
summarize(
gini = sum(x_i * 2(sum(s_i)))
) |>
pull(gini)
gini <- Gini(x_i$x_i, weights = s_i$s_i)
install.packages("DescTools")
library(DescTools)
gini <- Gini(x_i$x_i, weights = s_i$s_i)
gini <- Gini(s_i$s_i)
gini <- location_quotients |>
mutate(
s_j = lead(s_i)
)
View(location_quotients)
View(gini)
gini <- location_quotients |>
mutate(
s_j = lag(s_i)
)
gini <- location_quotients |>
mutate(
s_j = lag(s_i),
gini = 1 - sum(x_i(s_i + 2(sum(s_j))))
)
gini <- location_quotients |>
mutate(
s_j = lag(s_i),
gini = 1 - sum(x_i * (s_i + 2(sum(s_j))))
)
?sum
# from slide notes:
# location quotient Li = si/xi shows a location's level of specialization
# where si is a location's share of music places
# and xi is share of restaurants and bars
# we can compare across cities.
TOTAL_RB <- restaurants_and_bars |>
nrow()
TOTAL_MUSIC <- restaurants_and_bars |>
filter(music_treatment == 1) |>
nrow()
x <- restaurants_and_bars |>
group_by(city) |>
summarize(
num_rb = n()
) |>
mutate(
x = num_rb / TOTAL_RB
)
s <- restaurants_and_bars |>
filter(music_treatment == 1) |>
group_by(city) |>
summarize(
num_music = n()
) |>
mutate(
s = num_music / TOTAL_MUSIC
)
location_quotients <- x |>
inner_join(s, by = "city") |>
relocate(city, num_music, num_rb, s, x) |>
mutate(
l = s / x
)
?rowwise
compute_gini_row <- location_quotients |>
rowwise() |>
mutate(
row_gini = x * (s + 2(s))
)
compute_gini_row <- location_quotients |>
rowwise() |>
mutate(
row_gini = x * s
)
View(compute_gini_row)
compute_gini_row <- location_quotients |>
rowwise() |>
mutate(
row_gini = x * (s)
)
compute_gini_row <- location_quotients |>
rowwise() |>
mutate(
row_gini = x * (s + 2 * (sum(s)))
)
location_quotients <- location_quotients |>
mutate(
s_j = sum(s)
)
View(restaurants_and_bars)
# restaurants_and_bars ----------------------------------------------------
restaurants_and_bars <- cleaned_business_data |>
filter(restaurant_or_bar == 1) |>
select(!restaurant_or_bar) |>
relocate(categories)
load("~/Projects/spatial_dist_of_music/code/yelp_data_work/review_and_business.RData")
# script for filtering businesses down to those that offer food and/or drink
# based on a dictionary. Filtering is by Yelp classified "category"
library(tidyverse)
library(writexl)
library(readxl)
# FILTER FOR CITIES ----------------------------------------
# this might be a slightly controversial step, but
# estimating the model for the entirety of the metro area
# in consideration is slightly outside the scope of this paper.
# While it would be interesting to see the differences between suburban and
# urban areas, filtering down to only the city level speeds up computation and
# makes interpretation a bit simpler.
cities <- c("boise","reno","santa barbara","tucson","st louis",
"indianapolis","philadelphia",
"nashville","new orleans","tampa")
# variable cleaning ------------------------------------------------------
filtered_business_data <- business_data |>
mutate(
# city cleaning
city = trimws(str_to_lower(city)),
city = str_replace_all(city, regex("\\."), ""),
) |>
filter(city %in% cities)
# Data Description --------------------------------------------------------
# we have the categories of businesses. These include cuisines such as
# Italian, Chinese, Home Repair, etc.
## What are the different types of categories available in the data? --------
businesses_by_categories <- filtered_business_data |>
separate_rows(categories, sep = ",") |>
mutate(categories = trimws(categories)) |>
relocate(categories)
## How many categories does a business have on average?
avg_category_counts <- businesses_by_categories |>
group_by(business_id) |>
count() |>
ungroup() |>
summarize(
avg = mean(n)
) |>
pull(avg) # about 4.5
# hence, adding a slightly conservative filter would likely
# only leave out non-bars/restaurants.
all_business_categories <- businesses_by_categories |>
select(categories) |>
filter(!is.na(categories)) |>
unique() # 1265 different categories
## export to excel for categorization. ---------
write_xlsx(all_business_categories, "business_categories.xlsx")
## After manually adding food/drink dummy -------
category_dummies <- read_excel("business_categories_with_dummy.xlsx")
# filter for restaurants/bars ----------------------------------------
restaurants_and_bars <- businesses_by_categories |>
inner_join(category_dummies, by = "categories") |>
filter(indicates_food_drink == 1) |>
group_by(business_id) |>
summarize(
categories = paste(categories, collapse = ", "),
across(everything(), first),
.groups = "drop"
) # 26926 restaurants and bars
# get a sample to evaluate filtering
sample_restaurants_and_bars <- restaurants_and_bars |>
slice_sample(n = 100)
# ids to filter reviews with
restaurant_and_bar_ids <- restaurants_and_bars |>
select(business_id) |>
pull(business_id)
## filter reviews ------------------------
restaurant_bar_reviews <- review_data |>
filter(business_id %in% restaurant_and_bar_ids) |> # 3 million total reviews
left_join(filtered_business_data |> select(business_id, city), by = "business_id") |>
mutate(year = year(date))
# explore data with random sample
sample_reviews <- restaurant_bar_reviews |>
slice_sample(n = 200)
# Define Sample Terms --------------------------
review_sample_size = 10000
# FIRST QUARTER: Explicit music performance terms (highest signal)
music_dict <- c(
"live music", "jazz band", "live band", "cover band", "tribute band",
"acoustic set", "open mic", "live entertainment", "live performer",
"house band", "resident DJ", "karaoke night", "music venue",
"concert", "jam session", "live jazz", "live blues", "live country"
)
# SECOND QUARTER: General music-related terms (medium-high signal)
second_quarter_terms <- c(
"jazz", "country", "blues", "music", "DJ", "band", "record",
"singer", "musician", "guitar", "piano", "drums", "saxophone",
"acoustic", "playlist", "jukebox", "sound system", "speakers",
"rock", "folk", "reggae", "soul", "funk", "hip hop", "electronic"
)
# THIRD QUARTER: Ambiguous/potential false positives (medium-low signal)
third_quarter_terms <- c(
"funky", "bass", "live", "hoping", "hope", "wish",
"vibe", "atmosphere", "energy", "mood", "tone",
"upbeat", "chill", "loud", "quiet", "background",
"entertaining", "lively", "ambiance", "scene"
)
# Sample ------------------------------------------------------------------
# helper for balanced slicing
balanced_slice <- function(data) {
result <- data |>
group_by(city, year) |>
slice_sample(prop = ((review_sample_size * 0.25) / nrow(restaurant_bar_reviews))) |>
ungroup()
return(result)
}
# set seed
set.seed(123)
# slice samples
first_quarter <- restaurant_bar_reviews |>
filter(str_detect(text, regex(paste(music_dict, collapse = "|"), ignore_case = TRUE))) |>
balanced_slice()
second_quarter <- restaurant_bar_reviews |>
filter(
!review_id %in% first_quarter$review_id,
str_detect(text, regex(paste(second_quarter_terms, collapse = "|"), ignore_case = TRUE))
) |>
balanced_slice()
third_quarter <- restaurant_bar_reviews |>
filter(
!review_id %in% c(first_quarter$review_id, second_quarter$review_id),
str_detect(text, regex(paste(third_quarter_terms, collapse = "|"), ignore_case = TRUE))
) |>
balanced_slice()
fourth_quarter <- restaurant_bar_reviews |>
filter(!review_id %in% c(first_quarter$review_id,
second_quarter$review_id,
third_quarter$review_id)) |>
balanced_slice()
# Combine
stratified_sample <- bind_rows(
first_quarter |> mutate(sample_stratum = "explicit_music"),
second_quarter |> mutate(sample_stratum = "general_music"),
third_quarter |> mutate(sample_stratum = "ambiguous"),
fourth_quarter |> mutate(sample_stratum = "random")
)
View(first_quarter)
View(stratified_sample)
View(second_quarter)
?slice_sample
load("~/Projects/spatial_dist_of_music/code/yelp_data_work/review_and_business.RData")
# script for filtering businesses down to those that offer food and/or drink
# based on a dictionary. Filtering is by Yelp classified "category"
library(tidyverse)
library(writexl)
library(readxl)
# FILTER FOR CITIES ----------------------------------------
# this might be a slightly controversial step, but
# estimating the model for the entirety of the metro area
# in consideration is slightly outside the scope of this paper.
# While it would be interesting to see the differences between suburban and
# urban areas, filtering down to only the city level speeds up computation and
# makes interpretation a bit simpler.
cities <- c("boise","reno","santa barbara","tucson","st louis",
"indianapolis","philadelphia",
"nashville","new orleans","tampa")
# variable cleaning ------------------------------------------------------
filtered_business_data <- business_data |>
mutate(
# city cleaning
city = trimws(str_to_lower(city)),
city = str_replace_all(city, regex("\\."), ""),
) |>
filter(city %in% cities)
# Data Description --------------------------------------------------------
# we have the categories of businesses. These include cuisines such as
# Italian, Chinese, Home Repair, etc.
## What are the different types of categories available in the data? --------
businesses_by_categories <- filtered_business_data |>
separate_rows(categories, sep = ",") |>
mutate(categories = trimws(categories)) |>
relocate(categories)
## How many categories does a business have on average?
avg_category_counts <- businesses_by_categories |>
group_by(business_id) |>
count() |>
ungroup() |>
summarize(
avg = mean(n)
) |>
pull(avg) # about 4.5
# hence, adding a slightly conservative filter would likely
# only leave out non-bars/restaurants.
all_business_categories <- businesses_by_categories |>
select(categories) |>
filter(!is.na(categories)) |>
unique() # 1265 different categories
## export to excel for categorization. ---------
write_xlsx(all_business_categories, "business_categories.xlsx")
## After manually adding food/drink dummy -------
category_dummies <- read_excel("business_categories_with_dummy.xlsx")
## export to excel for categorization. ---------
write_xlsx(all_business_categories, "data_output/business_categories.xlsx")
## After manually adding food/drink dummy -------
category_dummies <- read_excel("data_output/business_categories_with_dummy.xlsx")
# filter for restaurants/bars ----------------------------------------
restaurants_and_bars <- businesses_by_categories |>
inner_join(category_dummies, by = "categories") |>
filter(indicates_food_drink == 1) |>
group_by(business_id) |>
summarize(
categories = paste(categories, collapse = ", "),
across(everything(), first),
.groups = "drop"
) # 26926 restaurants and bars
# get a sample to evaluate filtering
sample_restaurants_and_bars <- restaurants_and_bars |>
slice_sample(n = 100)
# ids to filter reviews with
restaurant_and_bar_ids <- restaurants_and_bars |>
select(business_id) |>
pull(business_id)
# Read sample -------------------------------------------------------------
coded_sample <- read_excel("data_output/coding_sample_with_live_music.xlsx")
View(coded_sample)
# check discrepancies
chat_pass_one <- read_excel("data_output/chat_pass_one.xlsx")
View(chat_pass_one)
# check discrepancies
chat_pass_one <- read_excel("data_output/chat_pass_one.xlsx") |>
mutate(
chat_one = live_music
) |>
select(review_id, chat_one)
first_check <- coded_sample |>
inner_join(chat_pass_one, by = "review_id")
View(first_check)
first_check <- coded_sample |>
inner_join(chat_pass_one, by = "review_id") |>
relocate(chat_live_music, verified, chat_one)
discrep <- first_check |>
filter(
chat_live_music != verified || chat_one != verified
)
discrep <- first_check |>
filter(
chat_live_music != verified | chat_one != verified
)
View(discrep)
write_xlsx(discrep, "discrep.xlsx")
write_xlsx(discrep, "data_output/discrep.xlsx")
discrep <- first_check |>
filter(
chat_one != verified
)
write_xlsx(discrep, "data_output/discrep.xlsx")
# Read sample -------------------------------------------------------------
coded_sample <- read_excel("data_output/coding_sample_with_live_music.xlsx")
View(coded_sample)
# Read sample -------------------------------------------------------------
coded_sample <- read_excel("data_output/coding_sample_with_live_music.xlsx") |>
select(!chat_live_music) |>
rename(live_music = verified)
View(restaurants_and_bars)
names(restaurants_and_bars)
# count reviews per restaurant/bar ------------------------------------------
avg_num_reviews <- restaurants_and_bars |>
select(review_count) |>
summarize(
mean(review_count)
)
# count reviews per restaurant/bar ------------------------------------------
avg_num_reviews <- restaurants_and_bars |>
select(review_count) |>
summarize(
avg = mean(review_count)
) |>
pull(avg)
# count reviews per restaurant/bar ------------------------------------------
median_num_reviews <- restaurants_and_bars |>
select(review_count) |>
summarize(
median_reviews = median(review_count)
) |>
pull(median_reviews)
median_num_reviews <- restaurants_and_bars |>
select(review_count) |>
summarize(
median_reviews = median(review_count)
) |>
pull(median_reviews)
## filter reviews ------------------------
restaurant_bar_reviews <- review_data |>
filter(business_id %in% restaurant_and_bar_ids) |> # 3 million total reviews
left_join(filtered_business_data |> select(business_id, city), by = "business_id") |>
mutate(year = year(date))
# Prep for llm ------------------------------------------------------------
classified_sample <- read_excel("data_output/classification_sample_with_live_music.xlsx") |>
select(!chat_live_music)
# Prep for llm ------------------------------------------------------------
classified_sample <- read_excel("data_output/classification_sample_with_live_music.xlsx") |>
select(!chat_live_music)
View(classified_sample)
names(classified_sample)
# Prep for llm ------------------------------------------------------------
classified_sample <- read_excel("data_output/classification_sample_with_live_music.xlsx") |>
select(review_id, text, live_music)
View(classified_sample)
# write for finetuning
write_xlsx(classified_sample, "data_output/finetuning_reviews.csv")
# write for finetuning
write_xlsx(classified_sample, "data_output/finetuning_reviews.csv", fileEncoding = "UTF-8", row.names = FALSE)
# write for finetuning
write_csv(classified_sample, "data_output/finetuning_reviews.csv")
# clean errors:
classified_sample |>
select(live_music) |>
unique()
# clean errors:
classified_sample |>
select(live_music) |>
filter(is.na(live_music)) |>
length()
# clean errors:
classified_sample |>
filter(is.na(live_music))
# Prep for llm ------------------------------------------------------------
classified_sample <- read_excel("data_output/classification_sample_with_live_music.xlsx") |>
select(review_id, text, live_music)
# clean errors:
classified_sample |>
filter(is.na(live_music))
# clean errors:
classified_sample |>
select(live_music) |>
unique()
# clean errors:
classified_sample |>
filter(live_music == 9)
# Prep for llm ------------------------------------------------------------
classified_sample <- read_excel("data_output/classification_sample_with_live_music.xlsx") |>
select(review_id, text, live_music)
# clean errors:
classified_sample |>
select(live_music) |>
unique()
write_csv(classified_sample, "data_output/finetuning_reviews.csv")
# write entire dataset to csv:
write_csv(restaurant_bar_reviews, "data_output/all_restaurant_bar_reviews.csv")
# write entire dataset to csv:
write_csv(restaurant_bar_reviews, "data_output/all_restaurant_bar_reviews.csv")
